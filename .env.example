# LLM provider selection: openai | gemini | ollama
LLM_PROVIDER=openai

# Optional default model per provider
LLM_MODEL=

# Provider credentials
OPENAI_API_KEY=
GEMINI_API_KEY=

# Ollama config
OLLAMA_BASE_URL=http://localhost:11434
# Some clients use OLLAMA_HOST instead
# OLLAMA_HOST=http://localhost:11434
